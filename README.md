# Math 120 Final Project: Dune Text Analysis

## Project Overview

This project involves analyzing Frank Herbert's _Dune_, using word frequency and sentiment analysis to observe trends for each chapter. It will find the most common words per chapter, the most common words in the novel, and the changes in sentiment as the chapters progress. There will also be visualizations and organized data sets.

## Dataset

The data for this project originally comes from this pdf: https://i.4pcdn.org/tg/1439541465764.pdf.

## Google Colab Execution

`Final_Project.ipynb` should run automatically without any problems.

## Folder Structure
```
python_final_project/
├── data_raw/               # Raw, unprocessed data files
│   └── Dune.txt              # Original text of Dune
├── data/                   # Cleaned and processed data
│   ├── sentiment_and_word_count.csv  # Combined data on sentiments and word counts (generated by notebook)
│   └── separated_and_tokenized.csv   # Separated chapters and cleaned/tokenized words (generated by notebook)
├── src/                    # Helper functions and modules
│   ├── __init__.py           # Package initialization
│   ├── dataProcessing.py     # Data loading and cleaning functions
│   └── analysis.py           # Data analysis and visualization functions
├── notebooks/              # Project notebooks
│   └── Final_Project.ipynb   # Final analysis notebook
└── README.md               # This file
```
